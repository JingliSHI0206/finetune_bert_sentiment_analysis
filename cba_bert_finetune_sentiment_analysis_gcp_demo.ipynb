{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cba_bert_finetune_sentiment_analysis_gcp_demo.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMGLfYFM67X0zbg8ecdfIil",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JingliSHI0206/finetune_bert_sentiment_analysis/blob/main/cba_bert_finetune_sentiment_analysis_gcp_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sMw8jkinDQ07"
      },
      "source": [
        "# Fine-tune BERT for Sentiment Analysis on Google Cloud Platform"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tdRsrfPqEOO5"
      },
      "source": [
        "## 1. Setup Environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RtZ2PeXJD-Ei",
        "outputId": "a41c0c8e-5568-4602-8c5d-891f5c2b294d"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "from datetime import datetime\n",
        "\n",
        "PROJECT_ID = \"ajcai2021-text-summarization\"  \n",
        "APP_NAME = \"finetuned-bert-sentiment-analysis\"\n",
        "\n",
        "# The Google Cloud Notebook product has specific requirements\n",
        "IS_GOOGLE_CLOUD_NOTEBOOK = os.path.exists(\"/opt/deeplearning/metadata/env_version\")\n",
        "\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
        "\n",
        "# Google Cloud Notebook requires dependencies to be installed with '--user'\n",
        "USER_FLAG = \"\"\n",
        "if IS_GOOGLE_CLOUD_NOTEBOOK:\n",
        "    USER_FLAG = \"--user\"\n",
        "\n",
        "\n",
        "def get_timestamp():\n",
        "    return datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
        "\n",
        "\n",
        "TIMESTAMP = get_timestamp()\n",
        "print(f\"TIMESTAMP = {TIMESTAMP}\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TIMESTAMP = 20211118130043\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LeF3EU_QLLnI"
      },
      "source": [
        "!pip -q install {USER_FLAG} --upgrade transformers\n",
        "!pip -q install {USER_FLAG} --upgrade datasets\n",
        "!pip -q install {USER_FLAG} --upgrade tqdm\n",
        "!pip -q install {USER_FLAG} --upgrade cloudml-hypertune\n",
        "!pip -q install {USER_FLAG} --upgrade google-cloud-aiplatform"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eQsCg3ZnJPDh"
      },
      "source": [
        "### 1.1 Setup Google Authentication for Google Colab Notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bwsY2L4TMGlw"
      },
      "source": [
        "***\n",
        "<font color=\"red\">(**!!!** Skip 1.1 if GCP Notebook is used.) </font>\n",
        "***\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "va1D0G78KjNK"
      },
      "source": [
        "#os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]=\"ajcai2021-text-summarization-d01b3423bafd.json\"\n",
        "if \"google.colab\" in sys.modules:\n",
        "    from google.colab import auth\n",
        "    auth.authenticate_user()"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HX27stiTPPjh"
      },
      "source": [
        "### 1.2 Setup GCP Storage"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tyWEGPFwJNaR",
        "outputId": "cc465284-c5fe-4ff0-cf53-469d3f42f164"
      },
      "source": [
        "# create bucket to save model\n",
        "BUCKET_NAME = \"gs://bert-sentiment-analysis\" \n",
        "REGION = \"us-central1\" \n",
        "\n",
        "! gsutil mb -p $PROJECT_ID -l $REGION $BUCKET_NAME\n",
        "! gsutil ls -al $BUCKET_NAME"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating gs://bert-sentiment-analysis/...\n",
            "ServiceException: 409 A Cloud Storage bucket named 'bert-sentiment-analysis' already exists. Try another name. Bucket names must be globally unique across all Google Cloud projects, including those outside of your organization.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zpi2YIaaEfLP"
      },
      "source": [
        "## 2. Prepare Python Package Distribuation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_LuXxJ_LFR7y"
      },
      "source": [
        "PYTHON_PACKAGE_CODE_DIR = \"finetune_bert_sentiment_analysis\"\n",
        "\n",
        "PATH_PYTHON_DISTRIBUATION_LOCAL = f\"{PYTHON_PACKAGE_CODE_DIR}/dist/trainer-0.1.tar.gz\"\n",
        "PATH_PYTHON_DISTRIBUATION_GCS = (f\"{BUCKET_NAME}/code/trainer-0.1.tar.gz\")\n",
        "\n",
        "CUSTOM_TRAIN_IMAGE_URI = f\"gcr.io/{PROJECT_ID}/{APP_NAME}_train_k80\"\n",
        "MODULE_NAME = \"trainer.task\""
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "krCctpxQK2Rg"
      },
      "source": [
        ""
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DgweENonG7Th",
        "outputId": "41c6ed2b-a1d2-4810-dae1-6620dfb2c3e3"
      },
      "source": [
        "# pack source code\n",
        "!cd {PYTHON_PACKAGE_CODE_DIR} && python3 setup.py sdist --formats=gztar\n",
        "# upload package to gcs\n",
        "!gsutil cp {PATH_PYTHON_DISTRIBUATION_LOCAL} {PATH_PYTHON_DISTRIBUATION_GCS}\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running sdist\n",
            "running egg_info\n",
            "creating trainer.egg-info\n",
            "writing trainer.egg-info/PKG-INFO\n",
            "writing dependency_links to trainer.egg-info/dependency_links.txt\n",
            "writing requirements to trainer.egg-info/requires.txt\n",
            "writing top-level names to trainer.egg-info/top_level.txt\n",
            "writing manifest file 'trainer.egg-info/SOURCES.txt'\n",
            "reading manifest file 'trainer.egg-info/SOURCES.txt'\n",
            "writing manifest file 'trainer.egg-info/SOURCES.txt'\n",
            "warning: sdist: standard file not found: should have one of README, README.rst, README.txt, README.md\n",
            "\n",
            "running check\n",
            "warning: check: missing required meta-data: url\n",
            "\n",
            "warning: check: missing meta-data: either (author and author_email) or (maintainer and maintainer_email) must be supplied\n",
            "\n",
            "creating trainer-0.1\n",
            "creating trainer-0.1/trainer.egg-info\n",
            "copying files to trainer-0.1...\n",
            "copying setup.py -> trainer-0.1\n",
            "copying trainer.egg-info/PKG-INFO -> trainer-0.1/trainer.egg-info\n",
            "copying trainer.egg-info/SOURCES.txt -> trainer-0.1/trainer.egg-info\n",
            "copying trainer.egg-info/dependency_links.txt -> trainer-0.1/trainer.egg-info\n",
            "copying trainer.egg-info/requires.txt -> trainer-0.1/trainer.egg-info\n",
            "copying trainer.egg-info/top_level.txt -> trainer-0.1/trainer.egg-info\n",
            "Writing trainer-0.1/setup.cfg\n",
            "creating dist\n",
            "Creating tar archive\n",
            "removing 'trainer-0.1' (and everything under it)\n",
            "Copying file://finetune_bert_sentiment_analysis/dist/trainer-0.1.tar.gz [Content-Type=application/x-tar]...\n",
            "/ [1 files][  718.0 B/  718.0 B]                                                \n",
            "Operation completed over 1 objects/718.0 B.                                      \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Bpq4oOOMAZ7"
      },
      "source": [
        "# 3. Build Custom Docker and Push to *GCP*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aen1HlNTHQgx",
        "outputId": "54f2c8ba-d063-44f4-b960-528c2860a51f"
      },
      "source": [
        "\n",
        "!cd {PYTHON_PACKAGE_CODE_DIR}/ && docker build -f Dockerfile -t $CUSTOM_TRAIN_IMAGE_URI {PYTHON_PACKAGE_CODE_DIR}"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: docker: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e1Ugd6b_HYLo"
      },
      "source": [
        "!docker push $CUSTOM_TRAIN_IMAGE_URI"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bOPFoZe0MSLo"
      },
      "source": [
        "# 4. Start Training Job"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QnYTX8MPHby4"
      },
      "source": [
        "JOB_NAME = f\"job-{APP_NAME}-{get_timestamp()}\"\n",
        "\n",
        "print(f\"APP_NAME={APP_NAME}\")\n",
        "print(f\"CUSTOM_TRAIN_IMAGE_URI={CUSTOM_TRAIN_IMAGE_URI}\")\n",
        "print(f\"JOB_NAME={JOB_NAME}\")\n",
        "\n",
        "aiplatform.init(project=PROJECT_ID, staging_bucket=BUCKET_NAME)\n",
        "\n",
        "# configure the job with container image spec\n",
        "job = aiplatform.CustomContainerTrainingJob(display_name=f\"{JOB_NAME}\", container_uri=f\"{CUSTOM_TRAIN_IMAGE_URI}\")\n",
        "\n",
        "# define training code arguments\n",
        "training_args = [\"--num-epochs\", \"2\", \"--model-name\", \"finetuned-bert-classifier\"]\n",
        "# submit the custom job to Vertex training service\n",
        "model = job.run( replica_count=1, machine_type=\"n1-standard-4\",accelerator_type=\"NVIDIA_TESLA_K80\",accelerator_count=1,args=training_args,sync=False)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0yi5dEOsMXLA"
      },
      "source": [
        "# 5. Training Job Monitoring"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-ItLWD-MdKz"
      },
      "source": [
        "## Go to \"Vertex AI --> Training\""
      ]
    }
  ]
}